{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyZ6xFLgypPy"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJm1-V8CzEE1"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('variables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "HatWPZUyzQLR",
    "outputId": "733b3f1a-2c0e-46da-ffb2-7bb1923b4346"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Epic_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImEjyf6Y18ww"
   },
   "outputs": [],
   "source": [
    "# create lagged features for multivariate time series data\n",
    "def create_lagged_features(data, n_in=1, n_out=1, dropna=True):\n",
    "    n_vars = data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols = []\n",
    "\n",
    "    # Create lagged features for all variables (X)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "\n",
    "    # Create lagged features only for the first column (y)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.iloc[:, 0].shift(-i))\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "\n",
    "    if dropna:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg.values\n",
    "\n",
    "\n",
    "n_lag = 4\n",
    "\n",
    "n_steps = 8\n",
    "\n",
    "# Create lagged features\n",
    "data_lagged = create_lagged_features(df, n_in=n_lag, n_out=n_steps)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = data_lagged[:, :-n_steps]\n",
    "y = data_lagged[:, -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwa6AAjrFqWE"
   },
   "source": [
    "### Random Forest and Gradient boosted machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZ25qIo9WYP9"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(X) * 0.7)\n",
    "test_ind = range(train_size, len(X))\n",
    "\n",
    "y_pred_store = np.array([None] * len(X))\n",
    "y_test_array = np.array([])\n",
    "y_pred_array = np.array([])\n",
    "\n",
    "for forecast_ind in test_ind:\n",
    "    train_ind = list(range(0, forecast_ind))\n",
    "    X_train = X[train_ind]\n",
    "    X_test = X[forecast_ind].reshape(1, -1)\n",
    "    y_train = y[train_ind]\n",
    "    y_test = y[forecast_ind]\n",
    "\n",
    "    # Z-score\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Create the RF model / GBM model \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "#     model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_store[forecast_ind] = y_pred\n",
    "    y_test_array = np.append(y_test_array, y_test)\n",
    "    y_pred_array = np.append(y_pred_array, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdEn2M5wWmru",
    "outputId": "a3545482-54c1-4e3a-8d60-ea5330f117ec"
   },
   "outputs": [],
   "source": [
    "# Calculate the mean squared error on test sets\n",
    "\n",
    "mse = mean_squared_error(y_test_array, y_pred_array)\n",
    "print('Mean Squared Error for {} step: {}'.format(n_steps ,mse))\n",
    "\n",
    "mae = mean_absolute_error(y_test_array, y_pred_array)\n",
    "print('Mean Absolute Error for {} step: {}'.format(n_steps ,mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mn4-_AL7TmRV",
    "outputId": "91281e1d-78c0-40db-95c9-c6c7a055ba43"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test_array, y_pred_array)\n",
    "print('Mean Absolute Percentage Error for {} step: {:.2f}%'.format(n_steps,mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UE-hnhr_c1RL",
    "outputId": "5bc1a42d-5cf0-43a9-92be-b7d8b9e7c4ff"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "\n",
    "    # Calculate absolute error of the forecasted values\n",
    "    abs_err = np.abs(y_true[n_steps:] - y_pred[n_steps:])\n",
    "\n",
    "    # Calculate the mean absolute error of the forecasted values\n",
    "    mae = np.mean(abs_err)\n",
    "\n",
    "    # Calculate the mean absolute error for the in-sample h-step naive forecast\n",
    "    naive_forecast = y_true[:-n_steps]  # naive forecast shifts the series by h step\n",
    "    mae_naive = np.mean(np.abs(y_true[n_steps:] - naive_forecast))\n",
    "\n",
    "    # Calculate and return MASE\n",
    "    mase = mae / mae_naive\n",
    "\n",
    "    return mase\n",
    "\n",
    "mase = mean_absolute_scaled_error(y_test_array, y_pred_array)\n",
    "print('Mean Absolute Scaled Error for {} step: {:.2f}'.format(n_steps,mase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzhljIwcksN2"
   },
   "outputs": [],
   "source": [
    "# 8 forecasting window. different size of samples.\n",
    "# 1 week ahead: [0, 48, 100, 152, 204, 256, 309, 361, 413, 465, 517]\n",
    "# 2 week ahead: [0, 47, 99, 151, 203, 255, 308, 360, 412, 464, 516]\n",
    "# 3 week ahead: [0, 46, 98, 150, 202, 254, 307, 359, 411, 463, 515]\n",
    "# 4 week ahead: [0, 45, 97, 149, 201, 253, 306, 358, 410, 462, 514]\n",
    "# 5 week ahead: [0, 44, 96, 148, 200, 252, 305, 357, 409, 461, 513]\n",
    "# 6 week ahead: [0, 43, 95, 147, 199, 251, 304, 356, 408, 460, 512]\n",
    "# 7 week ahead: [0, 42, 94, 146, 198, 250, 303, 355, 407, 459, 511]\n",
    "# 8 week ahead: [0, 41, 93, 145, 197, 249, 302, 354, 406, 458, 510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "d2sw2g45UIEq",
    "outputId": "8aa33a17-390e-4b8e-9224-4e5dfbdcacf2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "# Set the x-axis limits\n",
    "plt.xlim(-30, len(X)+40)\n",
    "\n",
    "# Shade the left half of the figure in light blue\n",
    "first_test_index = test_ind[0]  # Get the index of the first test observation\n",
    "plt.axvspan(-30, first_test_index, facecolor='lightblue', alpha=0.4)\n",
    "\n",
    "# Create tick locations and labels\n",
    "tick_interval = 52\n",
    "# origin data is [0, 52, 104, 156, 208, 260, 313, 365, 417, 469, 521]\n",
    "tick_locations = np.array([0, 41, 93, 145, 197, 249, 302, 354, 406, 458, 510])\n",
    "tick_label_locations = tick_locations[:-1] + tick_interval / 2\n",
    "tick_labels = [f'{year:02d}' for year in range(9, 19)]\n",
    "\n",
    "plt.plot(y, label='Observed', linestyle='-', linewidth=0.6, alpha=1, color='black')\n",
    "plt.scatter(range(len(y_pred_store)), y_pred_store, label=F'Random forest {n_steps} week ahead forecast', marker='o', s=10, alpha=1, color='darkorchid')\n",
    "\n",
    "\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('IPDs ED Attendances', fontsize=12)\n",
    "\n",
    "plt.xticks(tick_locations)\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.gca().set_xticks(tick_label_locations, minor=True)\n",
    "plt.gca().set_xticklabels(tick_labels, minor=True)\n",
    "plt.gca().tick_params(axis='x', which='minor', length=0)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.savefig('RF8.tif', format='tif', dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z56P0EWLnGMC",
    "outputId": "071e8861-b927-4d21-d4bd-e090038172c8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "# Set the x-axis limits\n",
    "plt.xlim(-30, len(X)+40)\n",
    "\n",
    "# Shade the left half of the figure in light blue\n",
    "first_test_index = test_ind[0]  # Get the index of the first test observation\n",
    "plt.axvspan(-30, first_test_index, facecolor='lightblue', alpha=0.4)\n",
    "\n",
    "# Create tick locations and labels\n",
    "tick_interval = 52\n",
    "# origin data is [0, 52, 104, 156, 208, 260, 313, 365, 417, 469, 521]\n",
    "tick_locations = np.array([0, 41, 93, 145, 197, 249, 302, 354, 406, 458, 510])\n",
    "tick_label_locations = tick_locations[:-1] + tick_interval / 2\n",
    "tick_labels = [f'{year:02d}' for year in range(9, 19)]\n",
    "\n",
    "plt.plot(y, label='Observed', linestyle='-', linewidth=0.6, alpha=1, color='black')\n",
    "plt.scatter(range(len(y_pred_store)), y_pred_store, label=F'Gradient boosted machines {n_steps} week ahead forecast', marker='o', s=10, alpha=1, color='darkorchid')\n",
    "\n",
    "\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('IPDs ED Attendances', fontsize=12)\n",
    "\n",
    "plt.xticks(tick_locations)\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.gca().set_xticks(tick_label_locations, minor=True)\n",
    "plt.gca().set_xticklabels(tick_labels, minor=True)\n",
    "plt.gca().tick_params(axis='x', which='minor', length=0)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.savefig('GBM8.tif', format='tif', dpi=400)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
