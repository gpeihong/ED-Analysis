{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cW1ELIyjgE6G"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "id": "8F76ZbHMia-T",
    "outputId": "3d1b4fbe-55f5-42ad-c8aa-ed294b12ab6d"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('variables.csv')\n",
    "df = df.drop(columns=['Epic_week'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vh5kAIT6id2G",
    "outputId": "9f10e385-3fc6-4a36-eb0b-826c26dee8ec"
   },
   "outputs": [],
   "source": [
    "n_lag = 4\n",
    "n_steps = 8\n",
    "# Create lagged variables for all variables\n",
    "columns = list(df.columns)\n",
    "\n",
    "for col in columns:\n",
    "    for i in range(1, n_lag + 1):\n",
    "        df[f\"{col}_lag_{i}\"] = df[col].shift(i)\n",
    "\n",
    "# Drop rows with NaN\n",
    "df = df.dropna()\n",
    "\n",
    "# Only keep the target column when there is no lag\n",
    "df = df.drop(df.columns[1:50], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "gFGewZZci7Qx",
    "outputId": "de49af50-cfb6-4864-9f1e-57938d19d887"
   },
   "outputs": [],
   "source": [
    "df = df.iloc[:, :5]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zm1NpJOUjub2"
   },
   "outputs": [],
   "source": [
    "y = df['Infectious and Parasitic Diseases'].shift(-n_steps+1)\n",
    "y = y.dropna()\n",
    "if n_steps != 1:\n",
    "  df = df.iloc[:-n_steps+1, :]\n",
    "\n",
    "X = df.drop('Infectious and Parasitic Diseases', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iV7jLCKkl0c1"
   },
   "outputs": [],
   "source": [
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sXMghIxmIL1"
   },
   "outputs": [],
   "source": [
    "# Cross validation.\n",
    "train_size = int(len(X) * 0.7)\n",
    "test_ind = range(train_size, len(X))\n",
    "\n",
    "y_pred_store = np.array([None] * len(X))\n",
    "y_test_array = np.array([])\n",
    "y_pred_array = np.array([])\n",
    "\n",
    "for forecast_ind in test_ind:\n",
    "    train_ind = list(range(0, forecast_ind))\n",
    "    X_train = X[train_ind]\n",
    "    X_test = X[forecast_ind].reshape(1, -1)\n",
    "    y_train = y[train_ind]\n",
    "    y_test = y[forecast_ind]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_store[forecast_ind] = y_pred\n",
    "    y_test_array = np.append(y_test_array, y_test)\n",
    "    y_pred_array = np.append(y_pred_array, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSU13m62nKsK",
    "outputId": "0fa4ae05-298a-42e4-b74e-d84c2eb17bfd"
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test_array, y_pred_array)\n",
    "print('Mean Squared Error for {} step: {}'.format(n_steps ,mse))\n",
    "\n",
    "mae = mean_absolute_error(y_test_array, y_pred_array)\n",
    "print('Mean Absolute Error for {} step: {}'.format(n_steps ,mae))\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test_array, y_pred_array)\n",
    "print('Mean Absolute Percentage Error for {} step: {:.2f}%'.format(n_steps,mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNWaLLCa6Sru",
    "outputId": "19202dc9-f485-4e71-9935-0b3d5885a217"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "\n",
    "    # Calculate absolute error of the forecasted values\n",
    "    abs_err = np.abs(y_true[n_steps:] - y_pred[n_steps:])\n",
    "\n",
    "    mae = np.mean(abs_err)\n",
    "\n",
    "    # Calculate the mean absolute error for the in-sample h-step naive forecast\n",
    "    naive_forecast = y_true[:-n_steps]  # naive forecast shifts the series by h step\n",
    "    mae_naive = np.mean(np.abs(y_true[n_steps:] - naive_forecast))\n",
    "\n",
    "    mase = mae / mae_naive\n",
    "\n",
    "    return mase\n",
    "\n",
    "mase = mean_absolute_scaled_error(y_test_array, y_pred_array)\n",
    "print('Mean Absolute Scaled Error for {} step: {:.2f}'.format(n_steps,mase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTU-BPxxU-TX"
   },
   "outputs": [],
   "source": [
    "# 8 forecasting window. different size of samples.\n",
    "# 1 week ahead: [0, 48, 100, 152, 204, 256, 309, 361, 413, 465, 517]\n",
    "# 2 week ahead: [0, 47, 99, 151, 203, 255, 308, 360, 412, 464, 516]\n",
    "# 3 week ahead: [0, 46, 98, 150, 202, 254, 307, 359, 411, 463, 515]\n",
    "# 4 week ahead: [0, 45, 97, 149, 201, 253, 306, 358, 410, 462, 514]\n",
    "# 5 week ahead: [0, 44, 96, 148, 200, 252, 305, 357, 409, 461, 513]\n",
    "# 6 week ahead: [0, 43, 95, 147, 199, 251, 304, 356, 408, 460, 512]\n",
    "# 7 week ahead: [0, 42, 94, 146, 198, 250, 303, 355, 407, 459, 511]\n",
    "# 8 week ahead: [0, 41, 93, 145, 197, 249, 302, 354, 406, 458, 510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "RnYOgH1zKhDJ",
    "outputId": "a664b73f-969d-41de-d805-5553113de8ee"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "plt.xlim(-30, len(X)+40) # Set the x-axis limits\n",
    "\n",
    "# Shade the left half of the figure\n",
    "first_test_index = test_ind[0]  # Get the index of the first test observation\n",
    "plt.axvspan(-30, first_test_index, facecolor='lightblue', alpha=0.4)\n",
    "\n",
    "# Create tick locations and labels\n",
    "tick_interval = 52\n",
    "# origin data is [0, 52, 104, 156, 208, 260, 313, 365, 417, 469, 521]\n",
    "tick_locations = np.array([0, 41, 93, 145, 197, 249, 302, 354, 406, 458, 510])\n",
    "tick_label_locations = tick_locations[:-1] + tick_interval / 2\n",
    "tick_labels = [f'{year:02d}' for year in range(9, 19)]\n",
    "\n",
    "plt.plot(y, label='Observed', linestyle='-', linewidth=0.6, alpha=1, color='black')\n",
    "plt.scatter(range(len(y_pred_store)), y_pred_store, label=F'AutoRegressive model {n_steps} week ahead forecast', marker='o', s=10, alpha=1, color='darkorchid')\n",
    "\n",
    "\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('IPDs ED Attendances', fontsize=12)\n",
    "\n",
    "plt.xticks(tick_locations)\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.gca().set_xticks(tick_label_locations, minor=True)\n",
    "plt.gca().set_xticklabels(tick_labels, minor=True)\n",
    "plt.gca().tick_params(axis='x', which='minor', length=0)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.savefig('AR8.tif', format='tif', dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJji8sQSn9hV"
   },
   "source": [
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4VDJiqxyQD2",
    "outputId": "68bd0a1b-53d5-4d80-ed3f-f0070d972230"
   },
   "outputs": [],
   "source": [
    "Y = pd.Series(y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Jiu3PFSqMcY",
    "outputId": "2995df7c-bcc7-4ef7-b755-93d10937972a"
   },
   "outputs": [],
   "source": [
    "def naive_forecast(series):\n",
    "    return series.shift(n_steps)\n",
    "\n",
    "forecast = naive_forecast(Y)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Po_7lI3CsLf-"
   },
   "outputs": [],
   "source": [
    "y_test = np.array(Y[test_ind])\n",
    "forecast_test = np.array(forecast[test_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbUsApXuz9ET",
    "outputId": "e29a61c0-552c-4363-f53f-f456267d9b83"
   },
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, forecast_test)\n",
    "print('Mean Squared Error for {} step: {}'.format(n_steps ,mse))\n",
    "\n",
    "mae = mean_absolute_error(y_test, forecast_test)\n",
    "print('Mean Absolute Error for {} step: {}'.format(n_steps ,mae))\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, forecast_test)\n",
    "print('Mean Absolute Percentage Error for {} step: {:.2f}%'.format(n_steps,mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hOra6lWc0zQ0",
    "outputId": "a6c7a5f9-faec-49e8-b51d-b37217c29cdf"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "\n",
    "    abs_err = np.abs(y_true[n_steps:] - y_pred[n_steps:])\n",
    "    mae = np.mean(abs_err)\n",
    "\n",
    "    naive_forecast = y_true[:-n_steps]  # naive forecast shifts the series by h step\n",
    "    mae_naive = np.mean(np.abs(y_true[n_steps:] - naive_forecast))\n",
    "\n",
    "    mase = mae / mae_naive\n",
    "\n",
    "    return mase\n",
    "\n",
    "mase = mean_absolute_scaled_error(y_test, forecast_test)\n",
    "print('Mean Absolute Scaled Error for {} step: {:.2f}'.format(n_steps,mase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faxfjlC5cb5P"
   },
   "outputs": [],
   "source": [
    "forecast_arr = np.array(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "JmOM56P5QasO",
    "outputId": "2c7054c7-4b76-4bd0-be2f-d933f56e5cb6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "plt.xlim(-30, len(X)+40)\n",
    "\n",
    "# # Shade the left half of the figure\n",
    "# first_test_index = test_ind[0]  # Get the index of the first test observation\n",
    "# plt.axvspan(-30, first_test_index, facecolor='lightblue', alpha=0.4)\n",
    "\n",
    "# Create tick locations and labels\n",
    "tick_interval = 52\n",
    "# origin data is [0, 52, 104, 156, 208, 260, 313, 365, 417, 469, 521]\n",
    "tick_locations = np.array([0, 41, 93, 145, 197, 249, 302, 354, 406, 458, 510])\n",
    "tick_label_locations = tick_locations[:-1] + tick_interval / 2\n",
    "tick_labels = [f'{year:02d}' for year in range(9, 19)]\n",
    "\n",
    "plt.plot(y, label='Observed', linestyle='-', linewidth=0.6, alpha=1, color='black')\n",
    "plt.scatter(range(len(forecast_arr)), forecast_arr, label=F'Naive {n_steps} week ahead forecast', marker='o', s=10, alpha=1, color='darkorchid')\n",
    "\n",
    "\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('IPDs ED Attendances', fontsize=12)\n",
    "\n",
    "plt.xticks(tick_locations)\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.gca().set_xticks(tick_label_locations, minor=True)\n",
    "plt.gca().set_xticklabels(tick_labels, minor=True)\n",
    "plt.gca().tick_params(axis='x', which='minor', length=0)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.savefig('Naive8.tif', format='tif', dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbchJN0jhJkE"
   },
   "source": [
    "### RF and GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('variables.csv')\n",
    "df = df.drop(columns=['Epic_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lagged features for multivariate time series data\n",
    "def create_lagged_features(data, n_in=1, n_out=1, dropna=True):\n",
    "    n_vars = data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols = []\n",
    "\n",
    "    # Create lagged features for all variables (X)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "\n",
    "    # Create lagged features only for the first column (y)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.iloc[:, 0].shift(-i))\n",
    "\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "\n",
    "    if dropna:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg.values\n",
    "\n",
    "\n",
    "n_lag = 4\n",
    "\n",
    "n_steps = 8\n",
    "\n",
    "data_lagged = create_lagged_features(df, n_in=n_lag, n_out=n_steps)\n",
    "\n",
    "X = data_lagged[:, :-n_steps]\n",
    "y = data_lagged[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X) * 0.7)\n",
    "test_ind = range(train_size, len(X))\n",
    "\n",
    "y_pred_store = np.array([None] * len(X))\n",
    "y_test_array = np.array([])\n",
    "y_pred_array = np.array([])\n",
    "\n",
    "for forecast_ind in test_ind:\n",
    "    train_ind = list(range(0, forecast_ind))\n",
    "    X_train = X[train_ind]\n",
    "    X_test = X[forecast_ind].reshape(1, -1)\n",
    "    y_train = y[train_ind]\n",
    "    y_test = y[forecast_ind]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    " \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "#     model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_store[forecast_ind] = y_pred\n",
    "    y_test_array = np.append(y_test_array, y_test)\n",
    "    y_pred_array = np.append(y_pred_array, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse = mean_squared_error(y_test_array, y_pred_array)\n",
    "print('Mean Squared Error for {} step: {}'.format(n_steps ,mse))\n",
    "\n",
    "mae = mean_absolute_error(y_test_array, y_pred_array)\n",
    "print('Mean Absolute Error for {} step: {}'.format(n_steps ,mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test_array, y_pred_array)\n",
    "print('Mean Absolute Percentage Error for {} step: {:.2f}%'.format(n_steps,mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "\n",
    "    abs_err = np.abs(y_true[n_steps:] - y_pred[n_steps:])\n",
    "\n",
    "    mae = np.mean(abs_err)\n",
    "\n",
    "    naive_forecast = y_true[:-n_steps]  # naive forecast shifts the series by h step\n",
    "    mae_naive = np.mean(np.abs(y_true[n_steps:] - naive_forecast))\n",
    "\n",
    "    mase = mae / mae_naive\n",
    "\n",
    "    return mase\n",
    "\n",
    "mase = mean_absolute_scaled_error(y_test_array, y_pred_array)\n",
    "print('Mean Absolute Scaled Error for {} step: {:.2f}'.format(n_steps,mase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "# Set the x-axis limits\n",
    "plt.xlim(-30, len(X)+40)\n",
    "\n",
    "# Shade the left half of the figure in light blue\n",
    "first_test_index = test_ind[0]  # Get the index of the first test observation\n",
    "plt.axvspan(-30, first_test_index, facecolor='lightblue', alpha=0.4)\n",
    "\n",
    "# Create tick locations and labels\n",
    "tick_interval = 52\n",
    "# origin data is [0, 52, 104, 156, 208, 260, 313, 365, 417, 469, 521]\n",
    "tick_locations = np.array([0, 41, 93, 145, 197, 249, 302, 354, 406, 458, 510])\n",
    "tick_label_locations = tick_locations[:-1] + tick_interval / 2\n",
    "tick_labels = [f'{year:02d}' for year in range(9, 19)]\n",
    "\n",
    "plt.plot(y, label='Observed', linestyle='-', linewidth=0.6, alpha=1, color='black')\n",
    "plt.scatter(range(len(y_pred_store)), y_pred_store, label=F'Random forest {n_steps} week ahead forecast', marker='o', s=10, alpha=1, color='darkorchid')\n",
    "\n",
    "\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('IPDs ED Attendances', fontsize=12)\n",
    "\n",
    "plt.xticks(tick_locations)\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.gca().set_xticks(tick_label_locations, minor=True)\n",
    "plt.gca().set_xticklabels(tick_labels, minor=True)\n",
    "plt.gca().tick_params(axis='x', which='minor', length=0)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.savefig('RF8.tif', format='tif', dpi=400) # or GBM\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
